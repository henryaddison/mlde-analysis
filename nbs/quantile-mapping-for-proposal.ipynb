{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "340fb58d-86f5-49d8-b718-f624f6e152bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Effect of quantile mapping on GCM-driven samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3601c0-af4a-4585-94c7-af27ddda3ee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cftime\n",
    "from cmethods import CMethods\n",
    "import iris\n",
    "import iris.analysis.cartography\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import metpy.plots.ctables\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ef08da-00fc-4f22-be63-9eb6cc4304a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_period = \"present\"\n",
    "split = \"val\"\n",
    "samples_per_run = 3\n",
    "data_configs = {\n",
    "    \"CPM\": [\n",
    "        {\n",
    "            \"fq_model_id\": \"score-sde/subvpsde/xarray_cncsnpp_continuous/bham-4x_PslTV_random-season-IstanTsqrturrecen-shuffle-fix\",\n",
    "            \"checkpoint\": \"epoch-100\",\n",
    "            \"input_xfm\": \"stan\",\n",
    "            \"label\": \"Diffusion\",\n",
    "            \"dataset\": f\"bham_gcmx-4x_psl-temp-vort_random-season-{time_period}\",\n",
    "            \"deterministic\": False,\n",
    "        },\n",
    "        {\n",
    "            \"fq_model_id\": \"id-linpr\",\n",
    "            \"checkpoint\": \"epoch-0\",\n",
    "            \"input_xfm\": \"\",\n",
    "            \"label\": \"Coarsened CPM precip (interp)\",\n",
    "            \"deterministic\": True,\n",
    "            \"dataset\": f\"bham_gcmx-4x_linpr_random-season-{time_period}\",\n",
    "        },\n",
    "    ],\n",
    "    \"GCM\": [\n",
    "        {\n",
    "            \"fq_model_id\": \"score-sde/subvpsde/xarray_cncsnpp_continuous/bham-4x_PslTV_random-season-IstanTsqrturrecen-shuffle-fix\",\n",
    "            \"checkpoint\": \"epoch-100\",\n",
    "            \"input_xfm\": \"stan\",\n",
    "            \"label\": \"Diffusion\",\n",
    "            \"dataset\": f\"bham_60km-4x_psl-temp-vort_random-season-{time_period}\",\n",
    "            \"deterministic\": False,\n",
    "        },\n",
    "        {\n",
    "            \"fq_model_id\": \"score-sde/subvpsde/xarray_cncsnpp_continuous/bham-4x_PslTV_random-season-IstanTsqrturrecen-shuffle-fix\",\n",
    "            \"checkpoint\": \"epoch-100\",\n",
    "            \"input_xfm\": \"pixelmmsstan\",\n",
    "            \"label\": \"Diffusion bc inputs\",\n",
    "            \"dataset\": f\"bham_60km-4x_psl-temp-vort_random-season-{time_period}\",\n",
    "            \"deterministic\": False,\n",
    "        },\n",
    "        {\n",
    "            \"fq_model_id\": \"id-linpr\",\n",
    "            \"checkpoint\": \"epoch-0\",\n",
    "            \"input_xfm\": \"\",\n",
    "            \"label\": \"GCM precip (interp)\",\n",
    "            \"deterministic\": True,\n",
    "            \"dataset\": f\"bham_60km-4x_linpr_random-season-{time_period}\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "highlighted_cpm_models = [\"Diffusion\"]\n",
    "desc = \"\"\"\n",
    "Compare diffusion model (PslTV) with and without quantile mapping (and simple interpolation of LR precip as baseline)\n",
    "\"\"\"\n",
    "# the datasets to use for comparisons like PSD which need default datasets with CPM-based hi-res precip and GCM-based lo-res precip respectively\n",
    "simulation_pr_datasets = {\n",
    "    \"GCM\": f\"bham_60km-4x_linpr_random-season-{time_period}\",\n",
    "    \"CPM\": f\"bham_gcmx-4x_linpr_random-season-{time_period}\"\n",
    "}\n",
    "gcm_lr_lin_pr_dataset = f\"bham_60km-4x_linpr_random-season-{time_period}\"\n",
    "cpm_hr_pr_dataset = f\"bham_gcmx-4x_psl-temp-vort_random-season-{time_period}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838622c-1810-423d-b092-f05a1a3a0bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IPython.display.Markdown(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29054c18-a37d-473c-88d9-b0a301b210f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ea32e-4626-46c5-a7fe-5a4ddedb6309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def si_to_mmday(ds, varname):\n",
    "    # convert from kg m-2 s-1 (i.e. mm s-1) to mm day-1\n",
    "    return (ds[varname] * 3600 * 24).assign_attrs({\"units\": \"mm day-1\"})\n",
    "\n",
    "\n",
    "def open_samples_ds(\n",
    "    run_name,\n",
    "    checkpoint_id,\n",
    "    dataset_name,\n",
    "    input_xfm_key,\n",
    "    split,\n",
    "    num_samples,\n",
    "    deterministic,\n",
    "):\n",
    "    samples_filepath_pattern = os.path.join(\n",
    "        os.getenv(\"DERIVED_DATA\"),\n",
    "        \"workdirs\",\n",
    "        run_name,\n",
    "        f\"samples/{checkpoint_id}\",\n",
    "        dataset_name,\n",
    "        input_xfm_key,\n",
    "        split,\n",
    "        \"predictions-*.nc\",\n",
    "    )\n",
    "    sample_ds_list = [\n",
    "        xr.open_dataset(sample_filepath)\n",
    "        for sample_filepath in glob.glob(samples_filepath_pattern)[:num_samples]\n",
    "    ]\n",
    "    if len(sample_ds_list) == 0:\n",
    "        raise RuntimeError(f\"{samples_filepath_pattern} has no sample files\")\n",
    "    if not deterministic:\n",
    "        if len(sample_ds_list) < num_samples:\n",
    "            raise RuntimeError(\n",
    "                f\"{samples_filepath_pattern} does not have {num_samples} sample files\"\n",
    "            )\n",
    "\n",
    "        ds = xr.concat(sample_ds_list, dim=\"sample_id\")\n",
    "        ds = ds.isel(sample_id=range(num_samples))\n",
    "    else:\n",
    "        ds = sample_ds_list[0]\n",
    "\n",
    "    ds[\"pred_pr\"] = si_to_mmday(ds, \"pred_pr\")\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def open_split_ds(dataset_name, split):\n",
    "    ds = xr.open_dataset(\n",
    "        os.path.join(\n",
    "            os.getenv(\"DERIVED_DATA\"),\n",
    "            \"moose\",\n",
    "            \"nc-datasets\",\n",
    "            dataset_name,\n",
    "            f\"{split}.nc\",\n",
    "        )\n",
    "    )\n",
    "    ds[\"target_pr\"] = si_to_mmday(ds, \"target_pr\")\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def open_merged_split_datasets(sample_runs, split):\n",
    "    return xr.merge(\n",
    "        [\n",
    "            open_split_ds(dataset_name, split)\n",
    "            for dataset_name in set(\n",
    "                [sample_run[\"dataset\"] for sample_run in sample_runs]\n",
    "            )\n",
    "        ],\n",
    "        compat=\"override\",\n",
    "    )\n",
    "\n",
    "\n",
    "def open_concat_sample_datasets(sample_runs, split, samples_per_run):\n",
    "    samples_das = [\n",
    "        open_samples_ds(\n",
    "            run_name=sample_run[\"fq_model_id\"],\n",
    "            checkpoint_id=sample_run[\"checkpoint\"],\n",
    "            dataset_name=sample_run[\"dataset\"],\n",
    "            input_xfm_key=sample_run[\"input_xfm\"],\n",
    "            split=split,\n",
    "            num_samples=samples_per_run,\n",
    "            deterministic=sample_run[\"deterministic\"],\n",
    "        )[\"pred_pr\"]\n",
    "        for sample_run in sample_runs\n",
    "    ]\n",
    "\n",
    "    samples_ds = xr.concat(\n",
    "        samples_das, pd.Index([sr[\"label\"] for sr in sample_runs], name=\"model\")\n",
    "    )\n",
    "\n",
    "    return samples_ds\n",
    "\n",
    "\n",
    "def prep_eval_data(sample_runs, split, samples_per_run=3):\n",
    "    samples_ds = open_concat_sample_datasets(sample_runs, split, samples_per_run)\n",
    "\n",
    "    eval_ds = open_merged_split_datasets(sample_runs, split)\n",
    "\n",
    "    return xr.merge([samples_ds, eval_ds], join=\"inner\", compat=\"override\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a380ab7-f259-405a-b554-f399c8974fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_ds = { source: prep_eval_data(data_config, split, samples_per_run=samples_per_run) for source, data_config in data_configs.items() }\n",
    "merged_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f23c39-b8ab-43b4-90c6-9203338049ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# time period train and eval split truth (CPM precip) - train split used to compute the quantile mapping, eval split used for evaluation\n",
    "cpm_sim_pr_train = open_split_ds(cpm_hr_pr_dataset, \"train\")[\"target_pr\"]\n",
    "cpm_sim_pr_split = open_split_ds(cpm_hr_pr_dataset, split)[\"target_pr\"]\n",
    "\n",
    "\n",
    "# time period train split samples (Diffusion precip) - used to compute the quantile mapping\n",
    "configs_for_qm = list(filter(lambda x: x[\"label\"] in [\"Diffusion\", \"Diffusion bc inputs\"], data_configs[\"GCM\"]))\n",
    "gcm_ml_pred_pr_train = open_concat_sample_datasets(configs_for_qm, \"train\", 1).isel(sample_id=0)\n",
    "\n",
    "# time period evaluation split samples (Diffusion precip) - samples to which quantile mapping applied \n",
    "gcm_ml_pred_pr_split = merged_ds[\"GCM\"][\"pred_pr\"].sel(model=list(map( lambda x: x[\"label\"], configs_for_qm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b04df9-2df1-4991-bce1-85271f178c28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Quatile map eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a1c48-4142-425a-ada3-63eb0b5f8112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def qm_dom_aware(obs, simh, simp, n_quantiles=250, kind=\"+\"):\n",
    "    obs, simh, simp = np.array(obs), np.array(simh), np.array(simp)\n",
    "\n",
    "    global_max = max(np.amax(obs), np.amax(simh))\n",
    "    global_min = min(np.amin(obs), np.amin(simh))\n",
    "    \n",
    "    \n",
    "    obs_min = np.amin(obs)\n",
    "    obs_max = np.amax(obs)\n",
    "    wide = abs(obs_max - obs_min) / n_quantiles\n",
    "    xbins_obs = np.arange(obs_min, obs_max + wide, wide)\n",
    "    \n",
    "    simh_min = np.amin(simh)\n",
    "    simh_max = np.amax(simh)\n",
    "    wide = abs(simh_max - simh_min) / n_quantiles\n",
    "    xbins_simh = np.arange(simh_min, simh_max + wide, wide)\n",
    "    def get_cdf(x, xbins):\n",
    "        pdf, _ = np.histogram(x, xbins)\n",
    "        return np.insert(np.cumsum(pdf), 0, 0.0)\n",
    "    \n",
    "    cdf_obs = get_cdf(obs, xbins_obs)\n",
    "    cdf_simh = get_cdf(simh, xbins_simh)\n",
    "    \n",
    "    epsilon = np.interp(simp, xbins_simh, cdf_simh)\n",
    "\n",
    "    return np.interp(epsilon, cdf_obs, xbins_obs)\n",
    "\n",
    "def qm_vec(sim_train_da, ml_train_da, ml_eval_da, n_quantiles=250, qm_1d_comp_func=qm_dom_aware):\n",
    "    return (\n",
    "        xr.apply_ufunc(\n",
    "            qm_1d_comp_func,  # first the function\n",
    "            sim_train_da,  # now arguments in the order expected by the function\n",
    "            ml_train_da,\n",
    "            ml_eval_da,\n",
    "            kwargs=dict(n_quantiles=n_quantiles, kind=\"+\"),\n",
    "            input_core_dims=[\n",
    "                [\"time\"],\n",
    "                [\"time\"],\n",
    "                [\"time\"],\n",
    "            ],  # list with one entry per arg\n",
    "            output_core_dims=[[\"time\"]],\n",
    "            exclude_dims=set(\n",
    "                (\"time\",)\n",
    "            ),  # dimensions allowed to change size. Must be set!\n",
    "            vectorize=True,\n",
    "        )\n",
    "        .transpose(\"time\", \"grid_latitude\", \"grid_longitude\")\n",
    "        .assign_coords(time=ml_eval_da[\"time\"])\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3e345-14a2-49b0-92cc-fbe21e250575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qm_output = []\n",
    "for model, model_da in gcm_ml_pred_pr_split.groupby(\"model\"):\n",
    "    def qm(gp):\n",
    "        return qm_vec(cpm_sim_pr_train, gcm_ml_pred_pr_train.sel(model=model), gp, qm_1d_comp_func=qm_dom_aware)\n",
    "        \n",
    "    qm_output.append(model_da.groupby(\"sample_id\").map(qm).rename(\"pred_pr\").assign_coords({'model': model+\" qm\"}))\n",
    "\n",
    "qm_gcm_ml_pred_pr_split = xr.concat(qm_output, dim=\"model\")\n",
    "# qm_adj_pred_pr = qm_adj_pred_pr.assign_coords({'model':('model', qm_adj_pred_pr['model'].astype(np.dtype(object)).data+\" qm\",qm_adj_pred_pr['model'].attrs)})\n",
    "# qm_adj_pred_pr = qm_adj_pred_pr.assign_coords({'model':('model',qm_adj_pred_pr['model'].astype(np.dtype(object)).data+\" qm\",qm_adj_pred_pr['model'].attrs)})\n",
    "\n",
    "\n",
    "merged_ds[\"GCM\"] = xr.merge([merged_ds[\"GCM\"], qm_gcm_ml_pred_pr_split.to_dataset()])\n",
    "merged_ds[\"GCM\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53fcd3e-b44f-445c-8279-4d090e9e7614",
   "metadata": {
    "tags": []
   },
   "source": [
    "## QQ and histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec1e3d-97a7-4cc9-9eeb-9c638a763fde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def freq_density_plot(ax, ds, target_pr, grouping_key=\"model\"):\n",
    "    pred_pr = ds[\"pred_pr\"]\n",
    "\n",
    "    hrange = (\n",
    "        min(pred_pr.min().values, target_pr.min().values),\n",
    "        max(pred_pr.max().values, target_pr.max().values),\n",
    "    )\n",
    "    _, bins, _ = target_pr.plot.hist(\n",
    "        ax=ax,\n",
    "        bins=50,\n",
    "        density=True,\n",
    "        color=\"black\",\n",
    "        alpha=0.2,\n",
    "        label=\"CPM\",\n",
    "        log=True,\n",
    "        range=hrange,\n",
    "    )\n",
    "    for group_value in pred_pr[grouping_key].values:\n",
    "        pred_pr.sel({grouping_key: group_value}).plot.hist(\n",
    "            ax=ax,\n",
    "            bins=bins,\n",
    "            density=True,\n",
    "            alpha=0.75,\n",
    "            histtype=\"step\",\n",
    "            label=f\"{group_value}\",\n",
    "            log=True,\n",
    "            range=hrange,\n",
    "            linewidth=2,\n",
    "            linestyle=\"-\",\n",
    "        )\n",
    "\n",
    "    ax.set_title(\"Log density of samples and CPM precip\")\n",
    "    ax.set_xlabel(\"Precip (mm day-1)\")\n",
    "    ax.tick_params(axis=\"both\", which=\"major\")\n",
    "    ax.legend()\n",
    "    # ax.set_aspect(aspect=1)\n",
    "\n",
    "def one_minus_cdf_plot(ax, ds, target_pr):\n",
    "    pred_pr = ds[\"pred_pr\"]\n",
    "    \n",
    "    hrange = (\n",
    "        min(pred_pr.min().values, target_pr.min().values),\n",
    "        max(pred_pr.max().values, target_pr.max().values),\n",
    "    )\n",
    "    _, bins, _ = target_pr.plot.hist(\n",
    "        ax=ax,\n",
    "        bins=50,\n",
    "        density=True,\n",
    "        cumulative=-1,\n",
    "        color=\"black\",\n",
    "        alpha=0.2,\n",
    "        label=\"CPM\",\n",
    "        log=True,\n",
    "        range=hrange,\n",
    "    )\n",
    "    for group_name, group in pred_pr.groupby(\"model\"):\n",
    "        group.plot.hist(\n",
    "            ax=ax,\n",
    "            bins=bins,\n",
    "            density=True,\n",
    "            cumulative=-1,\n",
    "            alpha=0.75,\n",
    "            histtype=\"step\",\n",
    "            label=f\"{group_name}\",\n",
    "            log=True,\n",
    "            range=hrange,\n",
    "            linewidth=2,\n",
    "            linestyle=\"-\",\n",
    "        )\n",
    "\n",
    "    ax.set_title(\"1 - CDF (log scale) of samples and CPM precip\")\n",
    "    ax.set_xlabel(\"Precip (mm day-1)\")\n",
    "    ax.tick_params(axis=\"both\", which=\"major\")\n",
    "    ax.legend()\n",
    "\n",
    "def qq_plot(\n",
    "    ax,\n",
    "    target_quantiles,\n",
    "    sample_quantiles,\n",
    "    grouping_key=\"model\",\n",
    "    title=\"Sample vs CPM quantiles\",\n",
    "    xlabel=\"CPM precip (mm/day)\",\n",
    "    ylabel=\"Sample precip (mm/day)\",\n",
    "    tr=200,\n",
    "    bl=0,\n",
    "    guide_label=\"Ideal\",\n",
    "    show_legend=True,\n",
    "    **lineplot_args,\n",
    "):\n",
    "    ax.plot(\n",
    "        [bl, tr],\n",
    "        [bl, tr],\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "        label=guide_label,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    for label, group_quantiles in sample_quantiles.groupby(grouping_key):\n",
    "        data = (\n",
    "            group_quantiles.squeeze()\n",
    "            .to_pandas()\n",
    "            .dropna()  # bit of a hack while have some models just for GCM and others just for CPM\n",
    "            .reset_index()\n",
    "        )\n",
    "        if grouping_key != \"sample_id\":\n",
    "            data = data.melt(\n",
    "                id_vars=\"quantile\", value_vars=list(group_quantiles[\"sample_id\"].values)\n",
    "            )\n",
    "        else:\n",
    "            data = data.melt(id_vars=\"quantile\", value_vars=[0])\n",
    "        data = data.merge(\n",
    "            target_quantiles.to_pandas().rename(\"cpm_quantile\").reset_index()\n",
    "        )\n",
    "\n",
    "        kwargs = (\n",
    "            dict(\n",
    "                errorbar=None,\n",
    "                marker=\"X\",\n",
    "                alpha=0.75,\n",
    "            )\n",
    "            | lineplot_args\n",
    "        )\n",
    "        sns.lineplot(\n",
    "            data=data,\n",
    "            x=\"cpm_quantile\",\n",
    "            y=\"value\",\n",
    "            ax=ax,\n",
    "            label=label,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    legend = ax.legend()\n",
    "    if not show_legend:\n",
    "        legend.remove()\n",
    "    ax.set_aspect(aspect=1)\n",
    "    \n",
    "def distribution_figure(\n",
    "    ds,\n",
    "    target_pr,\n",
    "    quantiles,\n",
    "    quantile_dims,\n",
    "    grouping_key=\"model\",\n",
    "    density_kwargs=dict(),\n",
    "    qq_kwargs=dict(),\n",
    "):\n",
    "    fig, axes = plt.subplot_mosaic(\n",
    "        [[\"Density\"]], figsize=(7, 3.5), constrained_layout=True\n",
    "    )\n",
    "\n",
    "    ax = axes[\"Density\"]\n",
    "    freq_density_plot(ax, ds, target_pr, grouping_key=grouping_key, **density_kwargs)\n",
    "    plt.show()\n",
    "\n",
    "    fig, axes = plt.subplot_mosaic(\n",
    "        [[\"Quantiles\"]], figsize=(3.5, 3.5), constrained_layout=True\n",
    "    )\n",
    "\n",
    "    ax = axes[\"Quantiles\"]\n",
    "\n",
    "    cpm_quantiles = target_pr.quantile(quantiles, dim=quantile_dims)\n",
    "\n",
    "    sample_quantiles = ds[\"pred_pr\"].quantile(quantiles, dim=quantile_dims)\n",
    "    qq_plot(\n",
    "        ax,\n",
    "        cpm_quantiles,\n",
    "        sample_quantiles,\n",
    "        grouping_key=grouping_key,\n",
    "        **({\"title\": None} | qq_kwargs),\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    fig, axes = plt.subplot_mosaic(\n",
    "        [ds[\"model\"].values], figsize=(10.5, 3.5), constrained_layout=True\n",
    "    )\n",
    "    for model, model_quantiles in sample_quantiles.groupby(\"model\"):\n",
    "        qq_plot(\n",
    "            axes[model],\n",
    "            cpm_quantiles,\n",
    "            model_quantiles,\n",
    "            title=model,\n",
    "            grouping_key=\"sample_id\",\n",
    "            alpha=0.5,\n",
    "            show_legend=False,\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a77091-f1a8-4829-9630-293158ecc739",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6701fa0-0736-4987-8b49-b1219cdf0416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for nq in [250]:\n",
    "    qm_gcm_ml_pred_pr_train = xr.concat([ \n",
    "        qm_vec(cpm_sim_pr_train, model_da, model_da, n_quantiles=nq).rename(\"pred_pr\").assign_coords({'model': model+\" qm\"})\n",
    "        for model, model_da in gcm_ml_pred_pr_train.groupby(\"model\") \n",
    "    ], dim=\"model\")\n",
    "    fig, axes = plt.subplot_mosaic(\n",
    "            [[\"Density\"], [\"CDF\"]], figsize=(7, 7), constrained_layout=True\n",
    "        )\n",
    "\n",
    "    ax = axes[\"Density\"]\n",
    "    freq_density_plot(\n",
    "        ax, \n",
    "        xr.merge([\n",
    "            gcm_ml_pred_pr_train, \n",
    "            qm_gcm_ml_pred_pr_train, \n",
    "        ]), \n",
    "        cpm_sim_pr_train,\n",
    "        grouping_key=\"model\")\n",
    "\n",
    "    ax = axes[\"CDF\"]\n",
    "    one_minus_cdf_plot(\n",
    "        ax, \n",
    "        xr.merge([\n",
    "            gcm_ml_pred_pr_train, \n",
    "            qm_gcm_ml_pred_pr_train, \n",
    "        ]), \n",
    "        cpm_sim_pr_train,\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc9d49a-aa1f-4c89-b4c5-ea5da58f71e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Eval set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1bb08d-fa04-40ea-bf7a-e0b8593842a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantiles = np.concatenate([np.linspace((1-10**(i+1))+(10**i), (1-10**i), 9) for i in range(-1, -8, -1)] + [[1.0]])\n",
    "\n",
    "distribution_figure(merged_ds[\"GCM\"], cpm_sim_pr_split, quantiles, quantile_dims=[\"time\", \"grid_latitude\", \"grid_longitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031020ad-8e2a-4125-a0a7-969f49d4e66f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49923222-9b46-448b-97a8-d7ab6a4e1e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def psd(batch):\n",
    "    # npix = batch.shape[1]\n",
    "    fourier = np.fft.fftshift(np.fft.fftn(batch, axes=(1, 2)), axes=(1, 2))\n",
    "    amps = np.abs(fourier) ** 2  # / npix**2\n",
    "    return amps\n",
    "\n",
    "def raspd(precip_da):\n",
    "    npix = precip_da[\"grid_latitude\"].size\n",
    "    fourier_amplitudes = psd(precip_da.values.reshape(-1, npix, npix))\n",
    "\n",
    "    kfreq = np.fft.fftshift(np.fft.fftfreq(npix)) * npix\n",
    "    kfreq2D = np.meshgrid(kfreq, kfreq)\n",
    "    knrm = np.sqrt(kfreq2D[0] ** 2 + kfreq2D[1] ** 2)\n",
    "    kbins = np.arange(-0.5, npix // 2 + 1, 1.0)\n",
    "    kvals = 0.5 * (kbins[1:] + kbins[:-1])\n",
    "\n",
    "    # radially average the means for each example\n",
    "    # take mean of amplitudes of each example once grouped into tori\n",
    "    # kbins defined equal-width (though not equal area) tori of Fourier plane with radius between start and end of each bin point\n",
    "    # knrm is size of k at each point in the plane (basically Euclidean distance in Fourier plane from centre point of the 64x64 array) so can determine which torus each member of fourier amplitudes belongs\n",
    "    Abins, _, _ = scipy.stats.binned_statistic(\n",
    "        knrm.flatten(),\n",
    "        fourier_amplitudes.reshape(-1, npix * npix),\n",
    "        statistic=\"mean\",\n",
    "        bins=kbins,\n",
    "    )\n",
    "    # take mean over all the examples\n",
    "    mean_Abins = np.mean(Abins, axis=0)\n",
    "\n",
    "    return kvals, mean_Abins\n",
    "\n",
    "def raspd_pysteps(precip_da):\n",
    "    npix = precip_da[\"grid_latitude\"].size\n",
    "    fourier_amplitudes = psd(precip_da.values.reshape(-1, npix, npix))\n",
    "\n",
    "    s1 = np.s_[-int(npix / 2) : int(npix / 2)]\n",
    "    s2 = np.s_[-int(npix / 2) : int(npix / 2)]\n",
    "    yc, xc = np.ogrid[s1, s2]\n",
    "\n",
    "    r_grid = np.sqrt(xc * xc + yc * yc).round()\n",
    "\n",
    "    r_range = np.arange(0, int(npix / 2))\n",
    "    freq = np.fft.fftfreq(npix) * npix\n",
    "    freq = freq[r_range]\n",
    "\n",
    "    pys_result = []\n",
    "    for r in r_range:\n",
    "        mask = r_grid == r\n",
    "        psd_vals = fourier_amplitudes[:, mask]\n",
    "        pys_result.append(np.mean(psd_vals))\n",
    "\n",
    "    mean_Abins = np.array(pys_result)\n",
    "\n",
    "    return freq, mean_Abins\n",
    "\n",
    "def plot_psd(cpm_hr_pr, gcm_lr_lin_pr, pred_pr):\n",
    "    fig, axd = plt.subplot_mosaic(\n",
    "        [[\"PSD\"]], tight_layout=True#, figsize=(12, 12)\n",
    "    )\n",
    "    ax = axd[\"PSD\"]\n",
    "\n",
    "    ax.loglog(*raspd(cpm_hr_pr), label=\"CPM pr\", color=\"black\", linewidth=5, linestyle=\"-.\", alpha=0.5)\n",
    "    ax.loglog(*raspd(gcm_lr_lin_pr), label=\"GCM interp. pr\", color=\"black\", linewidth=5, linestyle=\"-.\", alpha=0.5)\n",
    "\n",
    "    for model, precip_da in pred_pr.groupby(\"model\"):\n",
    "        ax.loglog(*raspd(precip_da), label=model)\n",
    "\n",
    "    ax.set_xlabel(\"$k$\")\n",
    "    ax.set_ylabel(\"$P(k)$\")\n",
    "    ax.legend(ncols=3)\n",
    "    ax.set_title(\"RAPSD\")\n",
    "\n",
    "    return fig, axd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cecd46a-a6d2-446c-9538-edceeaff2cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gcm_lr_lin_pr = (xr.open_dataset(\n",
    "    os.path.join(\n",
    "        os.getenv(\"DERIVED_DATA\"), \"moose\", \"nc-datasets\", gcm_lr_lin_pr_dataset, f\"{split}.nc\"\n",
    "    )\n",
    ")[\"linpr\"]*3600*24).assign_attrs({\"units\": \"mm day-1\"})\n",
    "\n",
    "cpm_hr_pr = (xr.open_dataset(\n",
    "    os.path.join(\n",
    "        os.getenv(\"DERIVED_DATA\"), \"moose\", \"nc-datasets\", cpm_hr_pr_dataset, f\"{split}.nc\"\n",
    "    )\n",
    ")[\"target_pr\"]*3600*24).assign_attrs({\"units\": \"mm day-1\"})\n",
    "\n",
    "plot_psd(cpm_hr_pr, gcm_lr_lin_pr, merged_ds[\"GCM\"][\"pred_pr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d049b33-0d30-4b20-b708-cece8de26c89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11e642-0e99-472c-85d9-5d0d8bb3ec00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cp_model_rotated_pole = ccrs.RotatedPole(pole_longitude=177.5, pole_latitude=37.5)\n",
    "\n",
    "precip_clevs = [0, 0.1, 1, 2.5, 5, 7.5, 10, 15, 20, 30, 40, 50, 70, 100, 150, 200]\n",
    "precip_cmap = matplotlib.colors.ListedColormap(\n",
    "    metpy.plots.ctables.colortables[\"precipitation\"][: len(precip_clevs) - 1],\n",
    "    \"precipitation\",\n",
    ")\n",
    "precip_norm = matplotlib.colors.BoundaryNorm(precip_clevs, precip_cmap.N)\n",
    "\n",
    "STYLES = {\n",
    "    \"precip\": {\"cmap\": precip_cmap, \"norm\": precip_norm},\n",
    "    \"logBlues\": {\"cmap\": \"Blues\", \"norm\": matplotlib.colors.LogNorm()},\n",
    "}\n",
    "\n",
    "def plot_map(da, ax, title=\"\", style=\"logBlues\", add_colorbar=False, **kwargs):\n",
    "    if style is not None:\n",
    "        kwargs = STYLES[style] | kwargs\n",
    "    pcm = da.plot.pcolormesh(ax=ax, add_colorbar=add_colorbar, **kwargs)\n",
    "    ax.set_title(title)\n",
    "    ax.coastlines()\n",
    "    return pcm\n",
    "\n",
    "    \n",
    "def plot_examples(ds, timestamps):\n",
    "    thetas = [925, 850, 700, 500, 250]\n",
    "    input_variables = [\"vorticity850\", \"psl\"]\n",
    "    for ts in timestamps:\n",
    "        grid_spec = [input_variables]\n",
    "        fig, axd = plt.subplot_mosaic(\n",
    "            grid_spec,\n",
    "            figsize=(12, 2.5),\n",
    "            constrained_layout=True,\n",
    "            subplot_kw={\"projection\": cp_model_rotated_pole},\n",
    "        )\n",
    "        fig.suptitle(f\"Inputs {ts}\")\n",
    "        for i, var in enumerate(input_variables):\n",
    "            plot_map(ds.sel(time=ts)[var], ax=axd[var], style=None, title=var, add_colorbar=False)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        grid_spec = [\n",
    "            [\"Target\"]\n",
    "            + [f\"{model} Name\"]\n",
    "            + [\n",
    "                f\"{model} Sample {sample_idx}\"\n",
    "                for sample_idx in range(len(ds[\"sample_id\"]))\n",
    "            ]\n",
    "            for model in ds[\"model\"].values\n",
    "        ]\n",
    "        fig, axd = plt.subplot_mosaic(\n",
    "            grid_spec,\n",
    "            figsize=(12, 10),\n",
    "            constrained_layout=True,\n",
    "            subplot_kw={\"projection\": cp_model_rotated_pole},\n",
    "        )\n",
    "        fig.suptitle(f\"Precip {ts}\")\n",
    "\n",
    "        ax = axd[f\"Target\"]\n",
    "        plot_map(\n",
    "            ds.sel(time=ts).isel(model=0)[\"target_pr\"],\n",
    "            ax,\n",
    "            title=f\"Simulation\",\n",
    "            cmap=precip_cmap,\n",
    "            norm=precip_norm,\n",
    "            add_colorbar=False,\n",
    "        )\n",
    "\n",
    "        for model in ds[\"model\"].values:\n",
    "            ax = axd[f\"{model} Name\"]\n",
    "            ax.text(x=0, y=0, s=model)\n",
    "            ax.set_axis_off()\n",
    "            for sample_idx in range(len(ds[\"sample_id\"].values)):\n",
    "                ax = axd[f\"{model} Sample {sample_idx}\"]\n",
    "                plot_map(\n",
    "                    ds.sel(model=model, time=ts).isel(sample_id=sample_idx)[\"pred_pr\"],\n",
    "                    ax,\n",
    "                    cmap=precip_cmap,\n",
    "                    norm=precip_norm,\n",
    "                    add_colorbar=False,\n",
    "                    title=f\"Sample\",\n",
    "                )\n",
    "\n",
    "        ax = fig.add_axes([1.05, 0.0, 0.05, 0.95])\n",
    "        cb = matplotlib.colorbar.Colorbar(ax, cmap=precip_cmap, norm=precip_norm)\n",
    "        cb.ax.set_yticks(precip_clevs)\n",
    "        cb.ax.set_yticklabels(precip_clevs)\n",
    "        cb.ax.tick_params(axis=\"both\", which=\"major\")\n",
    "        cb.ax.set_ylabel(\"Precip (mm day-1)\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48913f86-0dcf-4f6b-a45d-13c1adb8b26b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Coarsened-CPM-driven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9aa36a-723f-4bd5-9427-e37ae06537fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CPM - 2034-12-03\n",
    "\n",
    "cpm_samples_ds = merged_ds[\"CPM\"].sel(time=[cftime._cftime.Datetime360Day(2034, 12, 3, 12, 0, 0)], method=\"nearest\")\n",
    "plot_examples(cpm_samples_ds, cpm_samples_ds[\"time\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2171e5d2-de7d-41b8-a0f8-d16ac4482967",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GCM-driven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906cb278-391f-41b9-ae23-711573111cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GCM - 2022-10-21\n",
    "gcm_samples_ds = merged_ds[\"GCM\"].sel(time=[cftime._cftime.Datetime360Day(2022, 10, 21, 12, 0, 0)], method=\"nearest\")\n",
    "plot_examples(gcm_samples_ds, gcm_samples_ds[\"time\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97cc3a4-9275-44b4-b192-07cc5663a8f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
